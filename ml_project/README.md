# Структура проекта
```

├── LICENSE            <- Лицензия MIT.
│
├── setup.py           <- Позволяет поставить проект через `pip install -e .`
│
├── requirements.txt   <- Требуемые библиотеки.
│                         Можно их поставить так: `pip install -r requirements.txt`
│                         Но они ставятся через setup.py (см. выше).
│
├── configs            <- Конфигурационные файлы.
│   │
│   ├── report_logging.conf.yml
│   │                  <- Логи для report (генерация отчёта по исходному датасету).
│   │
│   ├── core_logging.conf.yml
│   │                  <- Конфиг логов, основной программы.
│   │
│   ├── logregr.yml    <- Конфиг для логистической регрессии.
│   │
│   └── random_forest.yml
│                      <- Конфиг для случайного леса (по умолчанию).
│
├── data
│   ├── raw            <- Исходные, неменяемые данные
│   ├── └── heart.csv
│   │
│   ├── processed      <- Обработанные данные, которые для fit/predict
│   ├── validate_part  <- Валидационная часть данных.
│   ├── y_pred         <- Предсказанные метки для части задания predict.
│   └── fake_data      <- Сгенерированные данные.


├── logs
│   ├── core.log       <- Логи основной программы.
│   └── report.log     <- Логи создания отчёта.
│
│
├── models             <- Обученные, готовые модели в .joblib формате.
│
│
├── report             <- Сгенерированный через ProfileReport отчёт по датасету. 
│   │                     Для данной задачи его вполне хватает.
│   ├── creating_report.py
│   └── profile_report.html
│
├── src                <- Исходный код проекта.
│   │
│   ├── core.py        <- Главный .py файл, его и надо запускать. Чуть ниже опишу как.
│   │
│   ├── enities        <- Набор "сущностей" в виде dataclass.
│   │   │
│   │   ├── all_train_params.py
│   │   │              <- Объединение всех параметров, что ниже в один dataclass.
│   │   │
│   │   ├── feature_params.py
│   │   │              <- Параметры датасета. Категориальные, числовые колонки и target.
│   │   │
│   │   ├── model_params.py
│   │   │              <- Параметры моделей. Логрегрессия и случайный лес.
│   │   │
│   │   └── train_test_split_parametrs.py
│   │                  <- Параметры train_test_split.
│   │
│   │
│   ├── features       <- Обработка сырых данных и преобразование в датасет для fit/predict.
│   │   └── build_features.py
│   │
│   └── fit_predict    <- Fit/predict обработанных данных.
│       │
│       ├── fit_model.py
│       └── predict.py
│  
└── tests              <- Тесты.

```

Установка и создание окружения в conda:
```
conda create -n $environment_name python=3.6
conda activate $environment_name
pip install -e .
```
Запуск всех тестов из ml_project:
```
pytest -v -p no:warnings tests
```
Доступен --help для запусков.
```
python src\core.py --help
python src\core.py fit_predict --help
python src\core.py predict --help
```
Для обучения пайлайна надо запускать:
```
python src\core.py fit_predict
==
python src\core.py fit_predict -c random_forest (по умолчанию)

python src\core.py fit_predict -c logregr
```
Где для -c, --config надо передать названия конфигурационного файла в configs без ".yml".

Для predict надо иметь валидационный датасет
(он будет автоматически сгенерирован при запуске предыдущей команды fit_predict).
Есть 2 параметра:

```
--dataset, -d
"data/validate_part/x_test.csv" (по умолчанию)
путь к датасету

--output, -o
"data/y_pred/y_pred.csv" (по умолчани)
путь к генерируемому файлу с предсказаниями 
```

:heavy_plus_sign: -2) Назовите ветку homework1 (1 балл)
:one:

:heavy_plus_sign: -1) положите код в папку ml_project
:one:

:heavy_plus_sign: 0) В описании к пулл реквесту описаны основные "архитектурные" и тактические решения, которые сделаны в вашей работе. В общем, описание что именно вы сделали и для чего, чтобы вашим ревьюерам было легче понять ваш код. (2 балла)
:three:

:heavy_plus_sign: 1) Выполнение EDA, закоммитьте ноутбук в папку с ноутбуками (2 баллов)
Вы так же можете построить в ноутбуке прототип(если это вписывается в ваш стиль работы)
Можете использовать не ноутбук, а скрипт, который сгенерит отчет, закоммитьте и скрипт и отчет (за это + 1 балл)  
*Насколько понимаю, использование pandas_profiling не противоречени условию задачи. Да и тут такие данные, что его хватает за глаза. Т.е. выглядит как 2 + 1)*
:six:

:heavy_plus_sign: 2) Проект имеет модульную структуру(не все в одном файле =) ) (2 баллов)  
*В разделе "Стуктура проекта" я более дал краткие комментарии по каждому модулю.*
:eight:

:heavy_plus_sign: 3) использованы логгеры (2 балла)
:one::zero:

:heavy_plus_sign: 4) написаны тесты на отдельные модули и на прогон всего пайплайна(3 баллов)
:one::three:

:heavy_plus_sign: 5) Для тестов генерируются синтетические данные, приближенные к реальным (3 баллов)
- можно посмотреть на библиотеки https://faker.readthedocs.io/en/, https://feature-forge.readthedocs.io/en/latest/
- можно просто руками посоздавать данных, собственноручно написанными функциями
как альтернатива, можно закоммитить файл с подмножеством трейна(это не оценивается)

*Я генерировал данные в test_core.py. Использовал для этого 2 способа: генерация данных из похожего распределения (для числовых использовал нормальное, а категориальные фейковые генерировал с той же вероятностью, с которой они встречались в исходном датасете (результат, как и предполагалась очень случайный). Второй способ &mdash; менял только числовые, добавляя к ним гауссиану.*
:one::six:

:heavy_plus_sign: 6) Обучение модели конфигурируется с помощью конфигов в json или yaml, закоммитьте как минимум 2 корректные конфигурации, с помощью которых можно обучить модель (разные модели, стратегии split, preprocessing) (3 балла)  
*random_forest и logregr*
:one::nine:

:heavy_plus_sign: 7) Используются датаклассы для сущностей из конфига, а не голые dict (3 балла) 
:two::two:

:heavy_minus_sign: 8) Используйте кастомный трансформер(написанный своими руками) и протестируйте его(3 балла)
:two::two: :penguin:

:heavy_plus_sign: 9) Обучите модель, запишите в readme как это предлагается (3 балла)
:two::five:

:heavy_plus_sign: 10) напишите функцию predict, которая примет на вход артефакт/ы от обучения, тестовую выборку(без меток) и запишет предикт, напишите в readme как это сделать (3 балла)  
*Описано выше, параметр predict у core.py.*
:two::eight:

:heavy_minus_sign: 11) Используется hydra  (https://hydra.cc/docs/intro/) (3 балла - доп баллы)
:two::eight: :penguin:

:heavy_plus_sign: 12) Настроен CI(прогон тестов, линтера) на основе github actions  (3 балла - доп баллы (будем проходить дальше в курсе, но если есть желание поразбираться - welcome)
:three::one:

:heavy_plus_sign: 13) Проведите самооценку, опишите, в какое колво баллов по вашему мнению стоит оценить вашу работу и почему (1 балл доп баллы)
:three::two:

*Насколько понимаю, суммарно получаю 32 балла (в лучшем случае).* :grimacing:



